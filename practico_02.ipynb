{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctico 2: Introducción al aprendizaje por refuerzos\n",
    "## Integrantes:\n",
    "    Analian\n",
    "    Kraupl\n",
    "    Piaggio\n",
    "    \n",
    "Curso Aprendizaje por Refuerzos, Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\n",
    "\n",
    "FaMAF, 2019\n",
    "\n",
    "\n",
    "## Actividades\n",
    "\n",
    "Se pide:\n",
    "\n",
    "1) Implementar [Double DQN (DDQN)](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12389/11847).\n",
    "\n",
    "2) Implementar [Dueling DDQN](https://arxiv.org/pdf/1511.06581.pdf).\n",
    "\n",
    "3) Cambiar el entorno por uno nuevo a elección\n",
    "\n",
    "4) Implementar [Prioritized Experience Replay (PER)](https://arxiv.org/pdf/1511.05952.pdf) (**Opcional**).\n",
    "\n",
    "**Comentar en un notebook lo realizado paso a paso, mostrando resultados parciales y finales. Y subirlo a un repositorio en GitHub** \n",
    "\n",
    "**Recomendación General**: No se sugiere hacer este TP desde jupyter notebook/lab sino desde un IDE estilo \"Pycharm\" o \"Visual Studio Code\", debido a que los algoritmos de RL suelen requerir un debug paso a paso, tanto para corregir errores como para entender mejor cómo funcionan los mismos.\n",
    "\n",
    "**Opcional**: Implementación de un agente DQN convolucional que aprende a jugar a Atari© Space Invaders© ([link](https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Deep%20Q%20Learning/Space%20Invaders/DQN%20Atari%20Space%20Invaders.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = 16, 8\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import gym\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from agents.utils.memory.ReplayMemory import ReplayMemory\n",
    "from agents.utils.memory.Transition import Transition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, _input_size: int, _output_size: int, _hidden_layers: int, _hidden_size: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.input = nn.Linear(_input_size, _hidden_size)\n",
    "        self.hidden_layers = _hidden_layers\n",
    "        self.hidden = []\n",
    "        for i in range(_hidden_layers):\n",
    "            layer = nn.Linear(_hidden_size, _hidden_size)\n",
    "            self.add_module('h'+str(i), layer)\n",
    "            self.hidden.append(layer)\n",
    "        self.output = nn.Linear(_hidden_size, _output_size)\n",
    "\n",
    "        # init weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    #JPA Esto se llama cuando se hace model(s) que es lo mismo que hacer model.forward(s)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        for i in range(self.hidden_layers):\n",
    "            x = F.relu(self.hidden[i](x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, env, n_episodes=3000, max_env_steps=None, gamma=0.9,\n",
    "                 epsilon=0.5, epsilon_min=0.05, epsilon_log_decay=0.001, alpha=1e-3,\n",
    "                 memory_size=10000, batch_size=256, c=10, hidden_layers=2, hidden_size=24,\n",
    "                 render=False, debug=False):\n",
    "\n",
    "        self.memory = ReplayMemory(capacity=memory_size)\n",
    "        self.env = env\n",
    "\n",
    "        # hyper-parameter setting\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_log_decay\n",
    "        self.alpha = alpha\n",
    "        self.n_episodes = n_episodes\n",
    "        self.batch_size = batch_size\n",
    "        self.c = c\n",
    "        if max_env_steps is not None:\n",
    "            self.env._max_episode_steps = max_env_steps\n",
    "        self.observation_space_size = env.observation_space.shape[0]\n",
    "        self.action_space_size = env.action_space.n\n",
    "\n",
    "        self.render = render\n",
    "        self.debug = debug\n",
    "        if debug:\n",
    "            self.loss_list = []\n",
    "        # if gpu is to be used\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Init model 1\n",
    "        # Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "        # is a Module which contains other Modules, and applies them in sequence to\n",
    "        # produce its output. Each Linear Module computes output from input using a\n",
    "        # linear function, and holds internal Tensors for its weight and bias.\n",
    "        # After constructing the model we use the .to() method to move it to the\n",
    "        # desired device.\n",
    "        self.model = Net(self.observation_space_size, self.action_space_size, hidden_layers, hidden_size) \\\n",
    "            .to(self.device)\n",
    "        \n",
    "        self.target = Net(self.observation_space_size, self.action_space_size, hidden_layers, hidden_size) \\\n",
    "            .to(self.device)\n",
    "        \n",
    "        self.target.load_state_dict(self.model.state_dict())\n",
    "        self.target.eval()\n",
    "        self.model.train()\n",
    "\n",
    "        # The nn package also contains definitions of popular loss functions; in this\n",
    "        # case we will use Mean Squared Error (MSE) as our loss function. Setting\n",
    "        # reduction='sum' means that we are computing the *sum* of squared errors rather\n",
    "        # than the mean; this is for consistency with the examples above where we\n",
    "        # manually compute the loss, but in practice it is more common to use mean\n",
    "        # squared error as a loss by setting reduction='elementwise_mean'.\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "        # Use the optim package to define an Optimizer that will update the weights of\n",
    "        # the model for us. Here we will use Adam; the optim package contains many other\n",
    "        # optimization algoriths. The first argument to the Adam constructor tells the\n",
    "        # optimizer which Tensors it should update.\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=alpha)\n",
    "\n",
    "    def choose_action(self, state, epsilon):\n",
    "        \"\"\"Chooses the next action according to the model trained and the policy\"\"\"\n",
    "\n",
    "        # exploits the current knowledge if the random number > epsilon, otherwise explores\n",
    "        if np.random.random() <= epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q = self.model(state)\n",
    "                argmax = torch.argmax(q)\n",
    "                return argmax.item()\n",
    "\n",
    "    def get_epsilon(self, episode):\n",
    "        \"\"\"Returns an epsilon that decays over time until a minimum epsilon value is reached; in this case the minimum\n",
    "        value is returned\"\"\"\n",
    "        return max(self.epsilon_min, self.epsilon * math.exp(-self.epsilon_decay * episode))\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"Previously stored (s, a, r, s') tuples are replayed (that is, are added into the model). The size of the\n",
    "        tuples added is determined by the batch_size parameter\"\"\"\n",
    "\n",
    "        transitions, _ = self.memory.sample(self.batch_size)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_next_states = torch.stack([s for s in batch.next_state if s is not None])\n",
    "\n",
    "        non_final_mask = torch.stack(batch.done)\n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action)\n",
    "        reward_batch = torch.stack(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.model(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        with torch.no_grad():\n",
    "            next_state_values = torch.zeros(self.batch_size, device=self.device)\n",
    "            next_state_values[non_final_mask] = self.target(non_final_next_states).max(1)[0].detach()\n",
    "            # Compute the expected Q values\n",
    "            expected_state_action_values = reward_batch + self.gamma * next_state_values\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_fn(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        if self.debug:\n",
    "            self.loss_list.append(loss)\n",
    "            \n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop that controls the execution of the agent\"\"\"\n",
    "\n",
    "        scores = []\n",
    "        mean_scores = []\n",
    "        j = 0  # used for model2 update every c steps\n",
    "        for e in range(self.n_episodes):\n",
    "            state = self.env.reset()\n",
    "            state = torch.tensor(state, device=self.device, dtype=torch.float)\n",
    "            done = False\n",
    "            cum_reward = 0\n",
    "            while not done:\n",
    "                action = self.choose_action(\n",
    "                    state,\n",
    "                    self.get_epsilon(e))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = torch.tensor(next_state, device=self.device, dtype=torch.float)\n",
    "\n",
    "                cum_reward += reward\n",
    "                self.memory.push(\n",
    "                    state,  #Converted to tensor in choose_action method\n",
    "                    torch.tensor([action], device=self.device),\n",
    "                    None if done else next_state,\n",
    "                    torch.tensor(reward, device=self.device).clamp_(-1, 1),\n",
    "                    torch.tensor(not done, device=self.device, dtype=torch.bool))\n",
    "\n",
    "                if self.memory.__len__() >= self.batch_size:\n",
    "                    self.replay()\n",
    "\n",
    "                state = next_state\n",
    "                j += 1\n",
    "\n",
    "                # update second model\n",
    "                if j % self.c == 0:\n",
    "                    self.target.load_state_dict(self.model.state_dict())\n",
    "                    self.target.eval()\n",
    "\n",
    "            scores.append(cum_reward)\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_scores.append(mean_score)\n",
    "            if e % 100 == 0 and self.debug:\n",
    "                print('[Episode {}] - Mean reward {}.'.format(e, mean_score))\n",
    "\n",
    "        # noinspection PyUnboundLocalVariable\n",
    "        print('[Episode {}] - Mean reward {}.'.format(e, mean_score))\n",
    "        return scores, mean_scores\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = torch.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] - Mean reward 11.0.\n",
      "[Episode 100] - Mean reward 54.881188118811885.\n",
      "[Episode 200] - Mean reward 60.527363184079604.\n",
      "[Episode 300] - Mean reward 62.46843853820598.\n",
      "[Episode 400] - Mean reward 64.25935162094763.\n",
      "[Episode 500] - Mean reward 64.55489021956087.\n",
      "[Episode 600] - Mean reward 67.15474209650583.\n",
      "[Episode 700] - Mean reward 69.92724679029958.\n",
      "[Episode 800] - Mean reward 73.3270911360799.\n",
      "[Episode 900] - Mean reward 76.35627081021087.\n",
      "[Episode 1000] - Mean reward 77.25674325674326.\n",
      "[Episode 1100] - Mean reward 80.13260672116257.\n",
      "[Episode 1200] - Mean reward 82.67360532889259.\n",
      "[Episode 1300] - Mean reward 87.83013066871638.\n",
      "[Episode 1400] - Mean reward 90.53961456102783.\n",
      "[Episode 1500] - Mean reward 93.21518987341773.\n",
      "[Episode 1600] - Mean reward 94.17489069331668.\n",
      "[Episode 1700] - Mean reward 96.86478542034098.\n",
      "[Episode 1800] - Mean reward 98.68850638534148.\n",
      "[Episode 1900] - Mean reward 101.18253550762756.\n",
      "[Episode 2000] - Mean reward 104.2823588205897.\n",
      "[Episode 2100] - Mean reward 106.55021418372203.\n",
      "[Episode 2200] - Mean reward 108.27941844616083.\n",
      "[Episode 2300] - Mean reward 109.46153846153847.\n",
      "[Episode 2400] - Mean reward 111.38650562265722.\n",
      "[Episode 2500] - Mean reward 113.17872850859656.\n",
      "[Episode 2600] - Mean reward 113.82045367166475.\n",
      "[Episode 2700] - Mean reward 115.57164013328396.\n",
      "[Episode 2800] - Mean reward 115.23241699393074.\n",
      "[Episode 2900] - Mean reward 116.68803860737677.\n",
      "[Episode 3000] - Mean reward 117.25958013995334.\n",
      "[Episode 3100] - Mean reward 118.96807481457594.\n",
      "[Episode 3200] - Mean reward 119.81537019681349.\n",
      "[Episode 3300] - Mean reward 121.56922144804605.\n",
      "[Episode 3400] - Mean reward 123.01381946486327.\n",
      "[Episode 3500] - Mean reward 123.57697800628392.\n",
      "[Episode 3600] - Mean reward 124.60011108025549.\n",
      "[Episode 3700] - Mean reward 125.78816536071332.\n",
      "[Episode 3800] - Mean reward 126.47671665351223.\n",
      "[Episode 3900] - Mean reward 126.89592412201999.\n",
      "[Episode 4000] - Mean reward 127.69357660584853.\n",
      "[Episode 4100] - Mean reward 128.40453547915143.\n",
      "[Episode 4200] - Mean reward 129.20590335634373.\n",
      "[Episode 4300] - Mean reward 129.72308765403395.\n",
      "[Episode 4400] - Mean reward 130.60304476255396.\n",
      "[Episode 4500] - Mean reward 131.23950233281494.\n",
      "[Episode 4600] - Mean reward 132.2608128667681.\n",
      "[Episode 4700] - Mean reward 133.24633056796426.\n",
      "[Episode 4800] - Mean reward 133.92980629035617.\n",
      "[Episode 4900] - Mean reward 134.71352785145888.\n",
      "[Episode 4999] - Mean reward 134.8484.\n"
     ]
    }
   ],
   "source": [
    "agent = DQN(gym.make('CartPole-v0'), n_episodes=5000, debug=True)\n",
    "scoresDQN, meanDQN = agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(meanDQN), label='DQN', c='#5c8cbc')\n",
    "plt.ylim(0, 200)\n",
    "plt.title('Recompensa promedio por episodio (DQN)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQN:\n",
    "    def __init__(self, env, n_episodes=3000, max_env_steps=None, gamma=0.9,\n",
    "                 epsilon=0.5, epsilon_min=0.05, epsilon_log_decay=0.001, alpha=1e-3,\n",
    "                 memory_size=10000, batch_size=256, c=10, hidden_layers=2, hidden_size=24,\n",
    "                 render=False, debug=False):\n",
    "\n",
    "        self.memory = ReplayMemory(capacity=memory_size)\n",
    "        self.env = env\n",
    "\n",
    "        # hyper-parameter setting\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_log_decay\n",
    "        self.alpha = alpha\n",
    "        self.n_episodes = n_episodes\n",
    "        self.batch_size = batch_size\n",
    "        self.c = c\n",
    "        if max_env_steps is not None:\n",
    "            self.env._max_episode_steps = max_env_steps\n",
    "        self.observation_space_size = env.observation_space.shape[0]\n",
    "        self.action_space_size = env.action_space.n\n",
    "\n",
    "        self.render = render\n",
    "        self.debug = debug\n",
    "        if debug:\n",
    "            self.loss_list = []\n",
    "        # if gpu is to be used\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Init model 1\n",
    "        # Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "        # is a Module which contains other Modules, and applies them in sequence to\n",
    "        # produce its output. Each Linear Module computes output from input using a\n",
    "        # linear function, and holds internal Tensors for its weight and bias.\n",
    "        # After constructing the model we use the .to() method to move it to the\n",
    "        # desired device.\n",
    "        self.model = Net(self.observation_space_size, self.action_space_size, hidden_layers, hidden_size) \\\n",
    "            .to(self.device)\n",
    "        \n",
    "        self.target = Net(self.observation_space_size, self.action_space_size, hidden_layers, hidden_size) \\\n",
    "            .to(self.device)\n",
    "        \n",
    "        self.target.load_state_dict(self.model.state_dict())\n",
    "        self.target.eval()\n",
    "        self.model.train()\n",
    "\n",
    "        # The nn package also contains definitions of popular loss functions; in this\n",
    "        # case we will use Mean Squared Error (MSE) as our loss function. Setting\n",
    "        # reduction='sum' means that we are computing the *sum* of squared errors rather\n",
    "        # than the mean; this is for consistency with the examples above where we\n",
    "        # manually compute the loss, but in practice it is more common to use mean\n",
    "        # squared error as a loss by setting reduction='elementwise_mean'.\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "        # Use the optim package to define an Optimizer that will update the weights of\n",
    "        # the model for us. Here we will use Adam; the optim package contains many other\n",
    "        # optimization algoriths. The first argument to the Adam constructor tells the\n",
    "        # optimizer which Tensors it should update.\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=alpha)\n",
    "\n",
    "    def choose_action(self, state, epsilon):\n",
    "        \"\"\"Chooses the next action according to the model trained and the policy\"\"\"\n",
    "\n",
    "        # exploits the current knowledge if the random number > epsilon, otherwise explores\n",
    "        if np.random.random() <= epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q = self.model(state)\n",
    "                argmax = torch.argmax(q)\n",
    "                return argmax.item()\n",
    "\n",
    "    def get_epsilon(self, episode):\n",
    "        \"\"\"Returns an epsilon that decays over time until a minimum epsilon value is reached; in this case the minimum\n",
    "        value is returned\"\"\"\n",
    "        return max(self.epsilon_min, self.epsilon * math.exp(-self.epsilon_decay * episode))\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"Previously stored (s, a, r, s') tuples are replayed (that is, are added into the model). The size of the\n",
    "        tuples added is determined by the batch_size parameter\"\"\"\n",
    "\n",
    "        transitions, _ = self.memory.sample(self.batch_size)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_next_states = torch.stack([s for s in batch.next_state if s is not None])\n",
    "\n",
    "        non_final_mask = torch.stack(batch.done)\n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action)\n",
    "        reward_batch = torch.stack(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.model(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        with torch.no_grad():\n",
    "            next_state_values = torch.zeros(self.batch_size, device=self.device)        \n",
    "            #next_state_values[non_final_mask] = self.target(non_final_next_states).max(1)[0].detach()\n",
    "            _, next_state_actions = self.model(non_final_next_states).max(1, keepdim=True)\n",
    "            next_state_values[non_final_mask] = self.target(non_final_next_states).gather(1, next_state_actions).squeeze()                                \n",
    "            # Compute the expected Q values\n",
    "            expected_state_action_values = reward_batch + self.gamma * next_state_values\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_fn(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        if self.debug:\n",
    "            self.loss_list.append(loss)\n",
    "            \n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop that controls the execution of the agent\"\"\"\n",
    "\n",
    "        scores = []\n",
    "        mean_scores = []\n",
    "        j = 0  # used for model2 update every c steps\n",
    "        for e in range(self.n_episodes):\n",
    "            state = self.env.reset()\n",
    "            state = torch.tensor(state, device=self.device, dtype=torch.float)\n",
    "            done = False\n",
    "            cum_reward = 0\n",
    "            while not done:\n",
    "                action = self.choose_action(\n",
    "                    state,\n",
    "                    self.get_epsilon(e))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = torch.tensor(next_state, device=self.device, dtype=torch.float)\n",
    "\n",
    "                cum_reward += reward\n",
    "                self.memory.push(\n",
    "                    state,  #Converted to tensor in choose_action method\n",
    "                    torch.tensor([action], device=self.device),\n",
    "                    None if done else next_state,\n",
    "                    torch.tensor(reward, device=self.device).clamp_(-1, 1),\n",
    "                    torch.tensor(not done, device=self.device, dtype=torch.bool))\n",
    "\n",
    "                if self.memory.__len__() >= self.batch_size:\n",
    "                    self.replay()\n",
    "\n",
    "                state = next_state\n",
    "                j += 1\n",
    "\n",
    "                # update second model\n",
    "                if j % self.c == 0:\n",
    "                    self.target.load_state_dict(self.model.state_dict())\n",
    "                    self.target.eval()\n",
    "\n",
    "            scores.append(cum_reward)\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_scores.append(mean_score)\n",
    "            if e % 100 == 0 and self.debug:\n",
    "                print('[Episode {}] - Mean reward {}.'.format(e, mean_score))\n",
    "\n",
    "        # noinspection PyUnboundLocalVariable\n",
    "        print('[Episode {}] - Mean reward {}.'.format(e, mean_score))\n",
    "        return scores, mean_scores\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] - Mean reward 37.0.\n",
      "[Episode 100] - Mean reward 81.57425742574257.\n",
      "[Episode 200] - Mean reward 64.6268656716418.\n",
      "[Episode 300] - Mean reward 54.840531561461795.\n",
      "[Episode 400] - Mean reward 50.942643391521194.\n",
      "[Episode 500] - Mean reward 49.6746506986028.\n",
      "[Episode 600] - Mean reward 50.58569051580699.\n",
      "[Episode 700] - Mean reward 49.31526390870185.\n",
      "[Episode 800] - Mean reward 49.69538077403246.\n",
      "[Episode 900] - Mean reward 49.3196448390677.\n",
      "[Episode 999] - Mean reward 50.003.\n"
     ]
    }
   ],
   "source": [
    "## Le bajo la cantidad de episodios porque demora mucho!\n",
    "agent = DDQN(gym.make('CartPole-v0'), n_episodes=1000, debug=True)\n",
    "scoresDDQN, meanDDQN = agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(meanDDQN), label='DQN', c='#5c8cbc')\n",
    "plt.ylim(0, 200)\n",
    "plt.title('Recompensa promedio por episodio (DDQN)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingNet(nn.Module):\n",
    "\n",
    "    def __init__(self, _input_size: int, _output_size: int, _hidden_layers: int, _hidden_size: int):\n",
    "        super(DuelingNet, self).__init__()\n",
    "        self.input = nn.Linear(_input_size, _hidden_size)\n",
    "        self.hidden_layers = _hidden_layers\n",
    "        self.hidden = []\n",
    "        for i in range(_hidden_layers):\n",
    "            layer = nn.Linear(_hidden_size, _hidden_size)\n",
    "            self.add_module('h'+str(i), layer)\n",
    "            self.hidden.append(layer)\n",
    "        #\n",
    "        self.advantage = nn.Linear(_hidden_size, _output_size)\n",
    "        self.output = nn.Linear(_hidden_size, _output_size)\n",
    "\n",
    "        # init weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        for i in range(self.hidden_layers):\n",
    "            x = F.relu(self.hidden[i](x))\n",
    "        \n",
    "        adv = F.relu(self.advantage(x))\n",
    "        x = self.output(x)\n",
    "        return x + adv - adv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN:\n",
    "    def __init__(self, env, n_episodes=3000, max_env_steps=None, gamma=0.9,\n",
    "                 epsilon=0.5, epsilon_min=0.05, epsilon_log_decay=0.001, alpha=1e-3,\n",
    "                 memory_size=10000, batch_size=256, c=10, hidden_layers=2, hidden_size=24,\n",
    "                 render=False, debug=False):\n",
    "\n",
    "        self.memory = ReplayMemory(capacity=memory_size)\n",
    "        self.env = env\n",
    "\n",
    "        # hyper-parameter setting\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_log_decay\n",
    "        self.alpha = alpha\n",
    "        self.n_episodes = n_episodes\n",
    "        self.batch_size = batch_size\n",
    "        self.c = c\n",
    "        if max_env_steps is not None:\n",
    "            self.env._max_episode_steps = max_env_steps\n",
    "        self.observation_space_size = env.observation_space.shape[0]\n",
    "        self.action_space_size = env.action_space.n\n",
    "\n",
    "        self.render = render\n",
    "        self.debug = debug\n",
    "        if debug:\n",
    "            self.loss_list = []\n",
    "        # if gpu is to be used\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Init model 1\n",
    "        # Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "        # is a Module which contains other Modules, and applies them in sequence to\n",
    "        # produce its output. Each Linear Module computes output from input using a\n",
    "        # linear function, and holds internal Tensors for its weight and bias.\n",
    "        # After constructing the model we use the .to() method to move it to the\n",
    "        # desired device.\n",
    "        self.model = DuelingNet(self.observation_space_size, self.action_space_size, hidden_layers, hidden_size) \\\n",
    "            .to(self.device)\n",
    "        self.target = DuelingNet(self.observation_space_size, self.action_space_size, hidden_layers, hidden_size) \\\n",
    "            .to(self.device)\n",
    "        self.target.load_state_dict(self.model.state_dict())\n",
    "        self.target.eval()\n",
    "        self.model.train()\n",
    "\n",
    "        # The nn package also contains definitions of popular loss functions; in this\n",
    "        # case we will use Mean Squared Error (MSE) as our loss function. Setting\n",
    "        # reduction='sum' means that we are computing the *sum* of squared errors rather\n",
    "        # than the mean; this is for consistency with the examples above where we\n",
    "        # manually compute the loss, but in practice it is more common to use mean\n",
    "        # squared error as a loss by setting reduction='elementwise_mean'.\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "        # Use the optim package to define an Optimizer that will update the weights of\n",
    "        # the model for us. Here we will use Adam; the optim package contains many other\n",
    "        # optimization algoriths. The first argument to the Adam constructor tells the\n",
    "        # optimizer which Tensors it should update.\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=alpha)\n",
    "\n",
    "    def choose_action(self, state, epsilon):\n",
    "        \"\"\"Chooses the next action according to the model trained and the policy\"\"\"\n",
    "\n",
    "        # exploits the current knowledge if the random number > epsilon, otherwise explores\n",
    "        if np.random.random() <= epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q = self.model(state)\n",
    "                argmax = torch.argmax(q)\n",
    "                return argmax.item()\n",
    "\n",
    "    def get_epsilon(self, episode):\n",
    "        \"\"\"Returns an epsilon that decays over time until a minimum epsilon value is reached; in this case the minimum\n",
    "        value is returned\"\"\"\n",
    "        return max(self.epsilon_min, self.epsilon * math.exp(-self.epsilon_decay * episode))\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"Previously stored (s, a, r, s') tuples are replayed (that is, are added into the model). The size of the\n",
    "        tuples added is determined by the batch_size parameter\"\"\"\n",
    "\n",
    "        transitions, _ = self.memory.sample(self.batch_size)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_next_states = torch.stack([s for s in batch.next_state if s is not None])\n",
    "\n",
    "        non_final_mask = torch.stack(batch.done)\n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action)\n",
    "        reward_batch = torch.stack(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.model(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        with torch.no_grad():\n",
    "            next_state_values = torch.zeros(self.batch_size, device=self.device)\n",
    "            next_state_values[non_final_mask] = self.target(non_final_next_states).max(1)[0].detach()\n",
    "            # Compute the expected Q values\n",
    "            expected_state_action_values = reward_batch + self.gamma * next_state_values\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_fn(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        if self.debug:\n",
    "            self.loss_list.append(loss)\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop that controls the execution of the agent\"\"\"\n",
    "\n",
    "        scores = []\n",
    "        mean_scores = []\n",
    "        j = 0  # used for model2 update every c steps\n",
    "        for e in range(self.n_episodes):\n",
    "            state = self.env.reset()\n",
    "            state = torch.tensor(state, device=self.device, dtype=torch.float)\n",
    "            done = False\n",
    "            cum_reward = 0\n",
    "            while not done:\n",
    "                action = self.choose_action(\n",
    "                    state,\n",
    "                    self.get_epsilon(e))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = torch.tensor(next_state, device=self.device, dtype=torch.float)\n",
    "\n",
    "                cum_reward += reward\n",
    "                self.memory.push(\n",
    "                    state,  #Converted to tensor in choose_action method\n",
    "                    torch.tensor([action], device=self.device),\n",
    "                    None if done else next_state,\n",
    "                    torch.tensor(reward, device=self.device).clamp_(-1, 1),\n",
    "                    torch.tensor(not done, device=self.device, dtype=torch.bool))\n",
    "\n",
    "                if self.memory.__len__() >= self.batch_size:\n",
    "                    self.replay()\n",
    "\n",
    "                state = next_state\n",
    "                j += 1\n",
    "\n",
    "                # update second model\n",
    "                if j % self.c == 0:\n",
    "                    self.target.load_state_dict(self.model.state_dict())\n",
    "                    self.target.eval()\n",
    "\n",
    "            scores.append(cum_reward)\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_scores.append(mean_score)\n",
    "            if e % 100 == 0 and self.debug:\n",
    "                print('[Episode {}] - Mean reward {}.'.format(e, mean_score))\n",
    "\n",
    "        # noinspection PyUnboundLocalVariable\n",
    "        print('[Episode {}] - Mean reward {}.'.format(e, mean_score))\n",
    "        return scores, mean_scores\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] - Mean reward 22.0.\n",
      "[Episode 100] - Mean reward 88.23762376237623.\n",
      "[Episode 200] - Mean reward 87.8905472636816.\n",
      "[Episode 300] - Mean reward 75.0299003322259.\n",
      "[Episode 400] - Mean reward 71.77057356608479.\n",
      "[Episode 500] - Mean reward 73.14171656686626.\n",
      "[Episode 600] - Mean reward 72.78036605657238.\n",
      "[Episode 700] - Mean reward 72.54065620542083.\n",
      "[Episode 800] - Mean reward 76.86766541822722.\n",
      "[Episode 900] - Mean reward 82.3795782463929.\n",
      "[Episode 999] - Mean reward 84.436.\n"
     ]
    }
   ],
   "source": [
    "## Le bajo la cantidad de episodios porque demora mucho!\n",
    "agent = DuelingDQN(gym.make('CartPole-v0'), n_episodes=1000, debug=True)\n",
    "scoresDuelingDDQN, meanDuelingDDQN = agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(meanDuelingDDQN), label='DQN', c='#5c8cbc')\n",
    "plt.ylim(0, 200)\n",
    "plt.title('Recompensa promedio por episodio (Dueling DDQN)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cambiamos el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] - Mean reward -200.0.\n",
      "[Episode 100] - Mean reward -200.0.\n",
      "[Episode 200] - Mean reward -200.0.\n",
      "[Episode 300] - Mean reward -200.0.\n",
      "[Episode 400] - Mean reward -200.0.\n",
      "[Episode 500] - Mean reward -199.8443113772455.\n",
      "[Episode 600] - Mean reward -198.86023294509152.\n",
      "[Episode 700] - Mean reward -196.39372325249644.\n",
      "[Episode 800] - Mean reward -196.5056179775281.\n",
      "[Episode 900] - Mean reward -196.89345172031076.\n",
      "[Episode 999] - Mean reward -197.101.\n"
     ]
    }
   ],
   "source": [
    "##  probamos con \n",
    "agent = DDQN(gym.make('MountainCar-v0'), n_episodes=1000, debug=True)\n",
    "newScoresDDQN, newMeanDDQN = agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(newScoresDDQN), label='DDQN', c='#5c8cbc')\n",
    "plt.ylim(0, 200)\n",
    "plt.title('Recompensa promedio por episodio (DDQN)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning] *",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
